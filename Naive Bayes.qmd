---
title: "Naive Bayes"
format: html
---

```{r}
#| include: false
library(tidymodels)
library(tidyverse)
library(vroom)
library(dplyr)
library(embed)
library(discrim)
library(naivebayes)
```

```{r}
#| include: false
train_data <- vroom("train.csv")
test_data <- vroom("test.csv")
```

```{r}
my_recipe <- recipe(ACTION ~ ., data=train_data) |>
  

#prepped_recipe <- prep(my_recipe)
#train_data_2 <- bake(prepped_recipe, new_data=train_data)
#vroom_write(x=train_data_2, file="./Baked Train Data.csv", delim=",")
```

```{r}
nb_model <- naive_Bayes(smoothness=1) %>% #smoothness - how wiggly is the resulting density, laplace - how much predictions are all being pulled into 0.5
  set_mode("classification") %>% 
  set_engine("naivebayes")

my_workflow <- workflow() |>
  add_recipe(my_recipe) |>
  add_model(nb_model) |>
  fit(data=train_data)
```

```{r}
#| eval: false
#| include: false
## Grid of values to tune over10
tuning_grid <- grid_regular(smoothness(), levels = 5) ## L^2 total tuning possibilities

## Split data for CV15
folds <- vfold_cv(train_data, v = 5, repeats=1)

## Run the CV18
CV_results <- my_workflow %>%
  tune_grid(resamples=folds, grid=tuning_grid, metrics=metric_set(accuracy, roc_auc))
```

```{r}
#| eval: false
#| include: false
## Find Best Tuning Parameters
bestTune <- CV_results %>%
  select_best(metric = "roc_auc")

## Finalize the Workflow & fit it
final_wf <-
  my_workflow %>%
  finalize_workflow(bestTune) %>%
  fit(data=train_data)
```


```{r}
## Predict11
amazon_predictions <- my_workflow %>%
  predict(new_data = test_data, type="prob")
```

```{r}
## Format the Predictions for Submission to Kaggle
kaggle_submission <- amazon_predictions %>%
  bind_cols(., test_data) %>% #Bind predictions with test data
  select(id, .pred_1) %>%
  rename(ACTION=.pred_1) 

vroom_write(x=kaggle_submission, file="./Naive_Bayes_PCA_Predictions.csv", delim=",")
```
